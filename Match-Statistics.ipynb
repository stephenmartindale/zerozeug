{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leela Zerozeug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "import sqlite3\n",
    "\n",
    "from PIL import Image\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as pyplot\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from src import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leela Zero Training Match Database\n",
    "db_path = 'data/leela-zero.db'\n",
    "\n",
    "# Confidence Level for Hypothesis Tests\n",
    "alpha = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resignation Rate\n",
    "\n",
    "While scrutinising the *Leela Zero* web pages, I noticed what seemed like an alarmingly high resignation rate. How large, exactly?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sqlite3.connect(db_path) as sql:\n",
    "    count_games = sql.execute(\"SELECT COUNT(*) FROM Game\").fetchone()[0]\n",
    "    count_resignations = sql.execute(\"SELECT COUNT(*) FROM Game WHERE resign=1\").fetchone()[0]\n",
    "    \n",
    "print(\"{0} of {1} games ({2:.4%}) ended with resignation.\".format(count_resignations, count_games, (count_resignations / count_games)))\n",
    "\n",
    "pyplot.figure()\n",
    "pyplot.pie([count_resignations, count_games - count_resignations],\n",
    "           labels = ['resigned', 'scored'], colors = ['xkcd:fawn', 'xkcd:kiwi'], explode = (0.01, 0),\n",
    "           autopct = '%1.1f%%', shadow=False, startangle=70)\n",
    "pyplot.axis('equal')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well. I wonder why so many match games end prematurely. These games are played *without* Dirichlet noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fairness Tests\n",
    "\n",
    "Here is a routine to test fairness using a *coin-toss* model in which various trials are modelled as *independent* Bernoulli trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_fairness(trials, p, successes, alpha, silent=False):\n",
    "    mu = trials * p\n",
    "    sigma = math.sqrt(trials * p * (1.0 - p))\n",
    "    delta = abs(mu - successes)\n",
    "    z_binomial = 2.0 * stats.binom.cdf(mu - delta, trials, p) if (delta > 0) else 1.0\n",
    "    z_normal = 2.0 * (1.0 - stats.norm.cdf((delta - 0.5) / sigma)) if (delta > 0) else 1.0\n",
    "    reject = (z_binomial < alpha)\n",
    "    \n",
    "    if not silent:\n",
    "        print(\"Expected number of successes after {0} Bernoulli trials (p = {1:.1%}): {2}\".format(trials, p, mu))\n",
    "        print(\"Observed successes after {0} Bernoulli trials: {1}\".format(trials, successes))\n",
    "        print(\"Probability of observing ≤ {0} or ≥ {1} successes: {2:.4%}    (binomial distribution)\".format((mu - delta), (mu + delta), z_binomial))\n",
    "        print(\"Probability of observing ≤ {0} or ≥ {1} successes: {2:.4%}    (normal approximation)\".format((mu - delta), (mu + delta), z_normal))\n",
    "        if reject:\n",
    "            print(\"At an α = {0} confidence level, we REJECT the null hypothesis that p = {1}.\".format(alpha, p))\n",
    "        else:\n",
    "            print(\"At an α = {0} confidence level, we have insufficient evidence to reject the null hypothesis that p = {1}.\".format(alpha, p))\n",
    "            \n",
    "    return reject"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a sanity check, let's apply the test to the scraped data in the simplest way imaginable. It is immediately apparent that the *nigiri* procedure is, at least, unbiased.\n",
    "\n",
    "<span style=\"color: red;\">(For all following tests, unless otherwise stated, it is assumed that *nigiri* is fair and that the stronger and weaker networks get equal opportunities to play as both colours within the scope of a match.)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sqlite3.connect(db_path) as sql:\n",
    "    count_games = sql.execute(\"SELECT COUNT(*) FROM Game\").fetchone()[0]\n",
    "    count_challenger_as_black = sql.execute(\"SELECT COUNT(*) FROM Game\"\n",
    "                                            \" JOIN Match ON Game.match_id = Match.id\"\n",
    "                                            \" WHERE Game.black = Match.challenger\").fetchone()[0]\n",
    "    \n",
    "print(\"In {0} of {1} games ({2:.4%}), the challenger took black.\".format(count_challenger_as_black, count_games, (count_challenger_as_black / count_games)))\n",
    "print()\n",
    "\n",
    "test_fairness(count_games, 0.5, count_challenger_as_black, alpha)\n",
    "\n",
    "pyplot.figure()\n",
    "pyplot.pie([count_challenger_as_black, count_games - count_challenger_as_black],\n",
    "           labels = ['black', 'white'], colors = ['lightcoral', 'lightskyblue'], explode = (0.01, 0),\n",
    "           autopct = '%1.4f%%', shadow=False, startangle=70)\n",
    "pyplot.axis('equal')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's test the assumption that *komi*, alone, makes the game of *Go* fair. Let's be naïeve and consider only global totals, weighting game results equally, regardless of the match in which they were played or the network that played them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sqlite3.connect(db_path) as sql:\n",
    "    (black_victories, white_victories) = sql.execute(\"SELECT SUM(case [victor] when 1 then 1 else 0 end) as [black], SUM(case [victor] when 2 then 1 else 0 end) as [white] FROM Game\").fetchone()\n",
    "    \n",
    "print(\"Black won {0} games; white won {1}.\".format(black_victories, white_victories))\n",
    "print()\n",
    "\n",
    "test_fairness((black_victories + white_victories), 0.5, black_victories, alpha)\n",
    "\n",
    "pyplot.figure()\n",
    "pyplot.pie([black_victories, white_victories],\n",
    "           labels = ['black', 'white'], colors = ['lightcoral', 'lightskyblue'], explode = (0.01, 0),\n",
    "           autopct = '%1.4f%%', shadow=False, startangle=70)\n",
    "pyplot.axis('equal')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's interesting: white appears to be favoured and the margin appears to be statistically significant. Taken by itself, this result could be enough to conclude that *Leela Zero* prefers white although it gives no indication of *why* this might be the case. The model used and the data-selection criteria are extremely naïeve, however -- we need to go deeper!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's restrict the query to the thirty most recent, completed matches -- about 30% of the available data -- and also repeat the hypothesis test for each match, independently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = 30\n",
    "\n",
    "match_count = 0\n",
    "match_black_victories = []\n",
    "match_white_victories = []\n",
    "match_dates = []\n",
    "match_rejects = []\n",
    "total_black_victories = 0\n",
    "total_white_victories = 0\n",
    "black_rejects = 0\n",
    "white_rejects = 0\n",
    "\n",
    "with sqlite3.connect(db_path) as sql:\n",
    "    cursor = sql.execute(\"SELECT Game.match_id, Match.start_date, SUM(case [victor] when 1 then 1 else 0 end) as [black], SUM(case [victor] when 2 then 1 else 0 end) as [white]\"\n",
    "                         \" FROM Game\"\n",
    "                         \" JOIN Match ON Game.match_id = Match.id\"\n",
    "                         \" WHERE Match.result is not null\"\n",
    "                         \" GROUP BY Game.match_id, Match.start_date\"\n",
    "                         \" ORDER BY Match.start_date DESC\"\n",
    "                         \" LIMIT ?\", [history])\n",
    "    \n",
    "    for r in cursor:\n",
    "        (match_id, start_date, black_victories, white_victories) = r\n",
    "        total_black_victories += black_victories\n",
    "        total_white_victories += white_victories\n",
    "        \n",
    "        reject = test_fairness((black_victories + white_victories), 0.5, black_victories, alpha, silent=True)\n",
    "        if (reject) and (black_victories > white_victories):\n",
    "            black_rejects = black_rejects + 1\n",
    "        elif (reject) and (white_victories > black_victories):\n",
    "            white_rejects = white_rejects + 1\n",
    "        \n",
    "        match_count = match_count + 1\n",
    "        match_black_victories.append(black_victories)\n",
    "        match_white_victories.append(white_victories)\n",
    "        match_dates.append(start_date)\n",
    "        match_rejects.append((max(black_victories, white_victories) + 10) if reject else None)\n",
    "\n",
    "print(\"Black won {0} games; white won {1}.\".format(total_black_victories, total_white_victories))\n",
    "print()\n",
    "\n",
    "test_fairness((total_black_victories + total_white_victories), 0.5, total_black_victories, alpha)\n",
    "\n",
    "pyplot.figure()\n",
    "pyplot.pie([total_black_victories, total_white_victories],\n",
    "           labels = ['black', 'white'], colors = ['lightcoral', 'lightskyblue'], explode = (0.01, 0),\n",
    "           autopct = '%1.4f%%', shadow=False, startangle=70)\n",
    "pyplot.axis('equal')\n",
    "pyplot.show()\n",
    "            \n",
    "match_index = np.arange(match_count)\n",
    "\n",
    "pyplot.figure(figsize=(12, 6))\n",
    "pyplot.bar(match_index, match_black_victories, 0.4, color='lightcoral', label='black')\n",
    "pyplot.bar(match_index + 0.4, match_white_victories, 0.4, color='lightskyblue', label='white')\n",
    "pyplot.scatter(match_index + 0.2, match_rejects, marker='x', color='red')\n",
    "\n",
    "pyplot.suptitle('Black-White Win-Rates')\n",
    "pyplot.title('(last {0} matches)'.format(history))\n",
    "pyplot.ylabel('victories')\n",
    "pyplot.xticks(match_index + 0.2, match_dates, rotation=90)\n",
    "pyplot.legend(bbox_to_anchor=(1.11, 1.0), loc='upper right', borderaxespad=0)\n",
    "pyplot.show()\n",
    "\n",
    "print()\n",
    "print(\"Data from {0} of {1} recent matches proved sufficient to reject the null hypothesis at α = {2}.\".format(sum(r is not None for r in match_rejects), len(match_rejects), alpha))\n",
    "print(\"{0} of these matches favoured black; {1} of these favoured white.\".format(black_rejects, white_rejects))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch Web Data\n",
    "\n",
    "Scrape http://zero.sjeng.org/ for data from Leela Zero's training matches and store that data in a Sqlite database that can be queried offline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "web.fetch_database(db_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
